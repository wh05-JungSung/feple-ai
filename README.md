# feple-ai: AI ê¸°ë°˜ í†µí™” í’ˆì§ˆ ë¶„ì„ ì‹œìŠ¤í…œ

[![Build Status](https://img.shields.io/badge/build-passing-brightgreen)](https://github.com)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**feple-ai**ëŠ” ìŒì„± í†µí™” ë‚´ìš©ì„ AI ëª¨ë¸ë¡œ ë¶„ì„í•˜ì—¬, ìƒë‹´ í’ˆì§ˆì„ ë‹¤ê°ë„ë¡œ í‰ê°€í•˜ëŠ” AI ë¶„ì„ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. STT(Speech-to-Text), í™”ì ë¶„ë¦¬, ìì—°ì–´ ì²˜ë¦¬(NLP), LLM ê¸°ìˆ ì„ í†µí•©í•˜ì—¬ í†µí™” ë‚´ìš©ì— ëŒ€í•œ ê°ê´€ì ì´ê³  ë°ì´í„° ê¸°ë°˜ì˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

## âœ¨ ì£¼ìš” ê¸°ëŠ¥ (Key Features)

-   **ğŸ”Š STT (Speech-to-Text)**: `faster-whisper`ë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ì •í™•í•˜ê²Œ ë³€í™˜í•©ë‹ˆë‹¤.
-   **ğŸ‘¥ í™”ì ë¶„ë¦¬ (Speaker Diarization)**: `simple-diarizer`ë¥¼ í†µí•´ ëŒ€í™” ì°¸ì—¬ìë“¤ì˜ ë°œí™”ë¥¼ ë¶„ë¦¬í•˜ê³ , í›„ì²˜ë¦¬ ë¡œì§ì„ í†µí•´ 'ìƒë‹´ì‚¬(Agent)'ì™€ 'ê³ ê°(Customer)' ì—­í• ì„ ëª…í™•íˆ êµ¬ë¶„í•©ë‹ˆë‹¤.
-   **ğŸ“Š ë‹¤ì°¨ì› í’ˆì§ˆ í‰ê°€ (Multi-dimensional Quality Assessment)**: ì •ëŸ‰ì  ì§€í‘œì™€ ì •ì„±ì  ì§€í‘œë¥¼ ëª¨ë‘ í™œìš©í•˜ì—¬ í†µí™” ë‚´ìš©ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
    -   **ë©”íƒ€ë°ì´í„°**:
        -   `session_id`: ê° ë¶„ì„ ì„¸ì…˜ì˜ ê³ ìœ  ID
        -   `mid_category` (ì£¼ì œ ë¶„ë¥˜): LLMì„ í†µí•´ í†µí™”ì˜ í•µì‹¬ ì£¼ì œë¥¼ ë¶„ë¥˜
        -   `result_label` (ìƒë‹´ ê²°ê³¼): LLMì„ í†µí•´ ìƒë‹´ì˜ ë§ˆë¬´ë¦¬ ìƒíƒœë¥¼ ë¶„ë¥˜
        -   `profane` (ë¹„ì†ì–´ ì‚¬ìš©): LLMì„ í†µí•´ ê³ ê°ì˜ ë¹„ì†ì–´ ì‚¬ìš© ì—¬ë¶€ë¥¼ ê°ì§€
    -   **ìƒë‹´ íƒœë„ ì§€í‘œ**:
        -   `honorific_ratio` (ì¡´ëŒ“ë§): í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ì˜ ì •í™•í•œ ì¡´ëŒ“ë§ ì‚¬ìš© ë¹„ìœ¨
        -   `positive/negative_word_ratio` (ê¸ì •/ë¶€ì •ì–´): KNU ê°ì„±ì‚¬ì „ ê¸°ë°˜ì˜ ê°ì„± ë¶„ì„
        -   `euphonious_word_ratio` (ì™„ê³¡ì–´/ì¿ ì…˜ì–´): ê³ ê° ë¶€ë‹´ì„ ì¤„ì—¬ì£¼ëŠ” í‘œí˜„ ì‚¬ìš© ë¹„ìœ¨
        -   `empathy_ratio` (ê³µê° í‘œí˜„): í˜•íƒœì†Œ ë° íŒ¨í„´ ë¶„ì„ ê¸°ë°˜ì˜ ê³µê° í‘œí˜„ ë¹„ìœ¨
        -   `apology_ratio` (ì‚¬ê³¼ í‘œí˜„): í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ì˜ ì‚¬ê³¼ í‘œí˜„ ë¹„ìœ¨
    -   **ëŒ€í™” íë¦„ ì§€í‘œ**:
        -   `avg_response_latency` (í‰ê·  ì‘ë‹µ ì†ë„): ê³ ê° ë°œí™” í›„ ìƒë‹´ì‚¬ ì‘ë‹µê¹Œì§€ì˜ í‰ê·  ì‹œê°„
        -   `interruption_count` (ê°€ë¡œì±„ê¸° íšŸìˆ˜): ìƒë‹´ì‚¬ê°€ ê³ ê°ì˜ ë§ì„ ëŠì€ íšŸìˆ˜
        -   `silence_ratio` (ì¹¨ë¬µ ë¹„ìœ¨): ì „ì²´ ëŒ€í™”ì—ì„œ ì¹¨ë¬µì´ ì°¨ì§€í•˜ëŠ” ë¹„ìœ¨
        -   `talk_ratio` (ë°œí™” ë¹„ìœ¨): ìƒë‹´ì‚¬ ëŒ€ë¹„ ê³ ê°ì˜ ë°œí™”ëŸ‰ ë¹„ìœ¨
    -   **LLM ê¸°ë°˜ ì •ì„± í‰ê°€**:
        -   `suggestions` (ë¬¸ì œ í•´ê²°ë ¥): OpenAI APIë¥¼ í†µí•´ ë¬¸ì œ í•´ê²° ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì ìˆ˜í™”
        -   `customer_sentiment_trend` (ê³ ê° ê°ì • ë³€í™”): ìƒë‹´ ì „í›„ ê³ ê°ì˜ ê°ì • ë³€í™” ì¶”ì´ ë¶„ì„

## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ ë° ì•„í‚¤í…ì²˜ (Tech Stack & Architecture)

### Backend

-   **Language**: `Python 3.12`
-   **AI/ML**: `PyTorch (+cu121)`, `faster-whisper`, `simple-diarizer`, `kiwipiepy`, `kss`, `OpenAI API`
-   **API Framework**: `FastAPI`
-   **Containerization**: `Docker` (NVIDIA CUDA 12.3 `cudnn9` Devel Image ê¸°ë°˜)

### Architecture

```
ì‚¬ìš©ì (Browser)
      |
      v
Vercel (React Frontend)
      |
      v
Vercel Serverless Function (/api/analyze)
      |
      v
Cloud Service (e.g., Google Cloud Run)
      |
      v
Docker Container (FastAPI Backend on GPU)
      |
      v
ë¶„ì„ ê²°ê³¼ (JSON) -> í”„ë¡ íŠ¸ì—”ë“œë¡œ ì—­ìˆœ ì „ë‹¬
```

## ğŸš€ ì‹œì‘í•˜ê¸° (Getting Started)

í”„ë¡œì íŠ¸ë¥¼ ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

### ì‚¬ì „ ìš”êµ¬ì‚¬í•­

-   [Git](https://git-scm.com/)
-   [Docker](https://www.docker.com/products/docker-desktop/)
-   NVIDIA ê·¸ë˜í”½ ì¹´ë“œ ë° ìµœì‹  ë“œë¼ì´ë²„

### Backend ì„¤ì • (Docker)

ë°±ì—”ë“œ API ì„œë²„ë¥¼ Docker ì»¨í…Œì´ë„ˆë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.

1.  **ë ˆí¬ì§€í† ë¦¬ í´ë¡ **
    ```bash
    git clone [https://github.com/your-username/feple-ai.git](https://github.com/your-username/feple-ai.git)
    cd feple-ai
    ```

2.  **í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ ìƒì„±**
    í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— `.env` íŒŒì¼ì„ ìƒì„±í•˜ê³ , OpenAIì—ì„œ ë°œê¸‰ë°›ì€ API í‚¤ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.
    ```env
    # .env
    OPENAI_API_KEY="sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
    ```

3.  **Docker ì´ë¯¸ì§€ ë¹Œë“œ**
    í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì—¬ Docker ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•©ë‹ˆë‹¤. ì•½ê°„ì˜ ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    ```bash
    docker build -t feple-ai .
    ```

4.  **Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰**
    ë¹Œë“œê°€ ì™„ë£Œë˜ë©´, GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ì»¨í…Œì´ë„ˆë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    ```bash
    docker run -p 8000:8000 --gpus all --env-file .env --name feple_api feple-ai
    ```

5.  **ë¡œì»¬ í…ŒìŠ¤íŠ¸**
    ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ `http://localhost:8000/docs` ë¡œ ì ‘ì†í•˜ì—¬ API ë¬¸ì„œë¥¼ í™•ì¸í•˜ê³ , ìŒì„± íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ì§ì ‘ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“– API ì‚¬ìš©ë²•

### `POST /analyze/`

ìŒì„± íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ í†µí™” í’ˆì§ˆ ë¶„ì„ ê²°ê³¼ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤.

-   **Request Body**:
    -   `Content-Type`: `multipart/form-data`
    -   `file`: ë¶„ì„í•  ì˜¤ë””ì˜¤ íŒŒì¼ (ì˜ˆ: `.wav`, `.mp3`)

-   **Success Response (200 OK)**:
    ```json
    {
        "processing_times": {
            "diarization": "25.31s",
            "stt": "15.78s",
            "merge": "0.01s",
            "post_processing": "0.02s",
            "metrics_calculation": "8.54s",
            "total": "49.66s"
        },
        "transcript": [
            {
                "text": "ìƒë‹´ì‚¬ ë‹µë³€",
                "speaker": "Agent",
                "start_time": 0.5,
                "end_time": 4.2
            },
            {
                "text": "ê³ ê° ì§ˆë¬¸",
                "speaker": "Customer",
                "start_time": 4.5,
                "end_time": 5.1
            }
        ],
        "metrics": {
            "session_id": "1751357467928",
            "mid_category": "ì£¼ë¬¸/ê²°ì œ/ì…ê¸ˆ í™•ì¸",
            "result_label": "ë§Œì¡±",
            "profane": 0,
            "honorific_ratio": 95.83,
            "positive_word_ratio": 10.15,
            "negative_word_ratio": 1.61,
            "euphonious_word_ratio": 20.83,
            "empathy_ratio": 4.17,
            "apology_ratio": 0.0,
            "suggestions": 0.6,
            "customer_sentiment_early": 0.25,
            "customer_sentiment_late": 0.5,
            "customer_sentiment_trend": 0.25,
            "avg_response_latency": 0.25,
            "interruption_count": 1,
            "silence_ratio": 0.11,
            "talk_ratio": 0.75
        }
    }
    ```
